{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART: BONUS\n",
    "\n",
    "Assume labels are not provided, but Udemy can find enough resources to label up to 300 courses. In other words, without looking at the label column, you can select up to 300 courses solely by examining the course_section_lecture_title column and ask Udemy to label it for you. Which 300 observations do you select and why?\n",
    "\n",
    "**Answer:** We'll choose a diverse set of 300 courses covering a wide range of topics to provide a comprehensive representation of the entire dataset. These selected courses will be informative for labeling purposes, capturing the variability and key patterns in the data.\n",
    "\n",
    "**Approach: Clustering**\n",
    "1. **Pre-Processing**\n",
    "2. **Vectorization**\n",
    "3. **Clustering**\n",
    "4. **Selection**\n",
    "\n",
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sharukh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sharukh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/sharukh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data and Removing Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseid</th>\n",
       "      <th>course_section_lecture_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8416</td>\n",
       "      <td>Beginners - How To Create iPhone And iPad Apps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8723</td>\n",
       "      <td>C Programming: iOS Development Starts Here!, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9287</td>\n",
       "      <td>Microsoft Excel 2010 Course Beginners/ Interme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9463</td>\n",
       "      <td>Programming Java for Beginners - The Ultimate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10318</td>\n",
       "      <td>Adobe Photoshop for Photographers, {Color Corr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   courseid                       course_section_lecture_title\n",
       "0      8416  Beginners - How To Create iPhone And iPad Apps...\n",
       "1      8723  C Programming: iOS Development Starts Here!, {...\n",
       "2      9287  Microsoft Excel 2010 Course Beginners/ Interme...\n",
       "3      9463  Programming Java for Beginners - The Ultimate ...\n",
       "4     10318  Adobe Photoshop for Photographers, {Color Corr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading Data into DataFrame\n",
    "data = pd.read_csv(\"udemy_ds_algos_exercise (1).csv\")\n",
    "data = data[['courseid','course_section_lecture_title']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing\n",
    "- Removing Stop Words\n",
    "- Lemitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "data['processed_text'] = data['course_section_lecture_title'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "Converting the Format from Text to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "-Assigining Required number of Clusters\n",
    "\n",
    "Note: Optimal number of clusters can be selected through Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering using K-means\n",
    "num_clusters = 5\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(X)\n",
    "# Add cluster labels \n",
    "data['cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection\n",
    "\n",
    "- Diversifying the data based on the number of clusters (5) and the required rows (300), which results in 300/5=60.\n",
    "- From each cluster, 60 rows should be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select courses from each cluster\n",
    "def select_courses_from_cluster(cluster_id, num_courses):\n",
    "    cluster_courses = data[data['cluster'] == cluster_id]\n",
    "    selected_courses = cluster_courses.sample(n=num_courses, random_state=42)\n",
    "    return selected_courses\n",
    "# Select 300 courses\n",
    "num_courses_per_cluster = 300 // num_clusters\n",
    "selected_courses = pd.DataFrame()\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    cluster_courses = select_courses_from_cluster(i, num_courses_per_cluster)\n",
    "    selected_courses = pd.concat([selected_courses, cluster_courses])\n",
    "\n",
    "# Reset the index of selected courses\n",
    "selected_courses.reset_index(drop=True, inplace=True)\n",
    "# Print the selected course IDs\n",
    "print(\"Selected Course IDs:\")\n",
    "print(selected_courses['courseid'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
